{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from abc import abstractmethod\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from scipy.special import gammaln  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_preds_correct(your_preds, sklearn_preds) -> bool:\n",
    "    return np.abs(your_preds - sklearn_preds).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_probs_correct(your_probs, sklearn_probs) -> bool:\n",
    "    return np.abs(your_probs - sklearn_probs).mean() < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не изменяйте код этого класса!\n",
    "class NaiveBayes:\n",
    "    def __init__(self, n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.params = dict()\n",
    "        \n",
    "    # --- PREDICTION ---\n",
    "        \n",
    "    def predict(self, x, return_probs=False):\n",
    "        \"\"\"\n",
    "        x - np.array размерности [N, dim], \n",
    "        где N - количество экземпляров данных, \n",
    "        dim -размерность одного экземпляра (количество признаков).\n",
    "        \n",
    "        Возвращает np.array размерности [N], содержащий номера классов для\n",
    "        соответствующих экземпляров.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for sample in x:\n",
    "            preds.append(\n",
    "                self.predict_single(sample, return_probs=return_probs)\n",
    "            )\n",
    "        \n",
    "        if return_probs:\n",
    "            return np.array(preds, dtype='float32')\n",
    "        \n",
    "        return np.array(preds, dtype='int32')\n",
    "    \n",
    "    # Совет: вниманительно изучите файл подсказок к данной лабораторной\n",
    "    # и сопоставьте код с описанной математикой байесовского классификатора.\n",
    "    def predict_single(self, x, return_probs=False) -> int:\n",
    "        \"\"\"\n",
    "        Делает предсказание для одного экземпляра данных.\n",
    "        \n",
    "        x - np.array размерности dim.\n",
    "        \n",
    "        Возвращает номер класса, которому принадлежит x.\n",
    "        \"\"\"\n",
    "        assert len(x.shape) == 1, f'Expected a vector, but received a tensor of shape={x.shape}'\n",
    "        marginal_prob = self.compute_marginal_probability(x)  # P(x) - безусловная вероятность появления x\n",
    "        \n",
    "        probs = []\n",
    "        for c in range(self.n_classes):                 # c - номер класса\n",
    "            prior = self.compute_prior(c)               # P(c) - априорная вероятность (вероятность появления класса)\n",
    "            likelihood = self.compute_likelihood(x, c)  # P(x|c) - вероятность появления x в предположении, что он принаждлежит c\n",
    "            \n",
    "            # Используем теорему Байесса для просчёта условной вероятности P(c|x)\n",
    "            # P(c|x) = P(c) * P(x|c) / P(x)\n",
    "            prob = prior * likelihood / marginal_prob\n",
    "            probs.append(prob)\n",
    "            \n",
    "        if return_probs:\n",
    "            return probs\n",
    "        \n",
    "        return np.argmax(probs)\n",
    "    \n",
    "    # Вычисляет P(x) - безусловная вероятность появления x.\n",
    "    @abstractmethod\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        pass\n",
    "    \n",
    "    # Вычисляет P(c) - априорная вероятность появления класса c.\n",
    "    @abstractmethod\n",
    "    def compute_prior(self, c) -> float:\n",
    "        pass\n",
    "    \n",
    "    # Вычисляет P(x|c) - вероятность наблюдения экземпляра x в предположении, что он принаждлежит c.\n",
    "    @abstractmethod\n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        pass\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._estimate_prior(y)\n",
    "        self._estimate_params(x, y)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _estimate_prior(self, y):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _estimate_params(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Наивный классификатор Байеса: гауссово распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите недостающий код, создайте и обучите модель. \n",
    "\n",
    "Пункты оценки:\n",
    "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
    "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(C_k|x) = P(x|theta) * P(C_k) / P(x)\n",
    "\n",
    "class NaiveGauss(NaiveBayes):\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        # Для просчёта безусловной вероятности используйте \n",
    "        # методы compute_prior и compute_likelihood.\n",
    "        # Напишите свой код здесь\n",
    "        return sum(self.compute_prior(c) * self.compute_likelihood(x, c) for c in range(self.n_classes))\n",
    "        \n",
    "    \n",
    "    def compute_prior(self, c) -> float:\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        return self.params['prior'][c]\n",
    "\n",
    "    \n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        \n",
    "        mean, var = self.params['mean'][c], self.params['var'][c]\n",
    "        return np.prod(1 / np.sqrt(2 * np.pi * var) * np.exp(-((x - mean) ** 2) / (2 * var)))\n",
    "\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def _estimate_prior(self, y):\n",
    "        # Значения априорных вероятностей сохраните в `params` с ключом 'prior'\n",
    "        self.params['prior'] = [np.mean(y == i) for i in range(self.n_classes)]\n",
    "    \n",
    "    def _estimate_params(self, x, y):\n",
    "        self.params['mean'] = np.array([x[y == c].mean(axis=0) for c in range(self.n_classes)])\n",
    "        self.params['var'] = np.array([x[y == c].var(axis=0) for c in range(self.n_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "my_ng_clf = NaiveGauss(n_classes=3)\n",
    "my_ng_clf.fit(x_train, y_train)\n",
    "Y = my_ng_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "accuracy_score(Y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (GaussianNB)\n",
    "sklearn_ng_clf = GaussianNB()\n",
    "sklearn_ng_clf.fit(x_train, y_train)\n",
    "sklearn_Y = sklearn_ng_clf.predict(x_test)\n",
    "\n",
    "accuracy_score(sklearn_Y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Упрощение наивного классификатора Байеса для гауссова распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберите из класса NaiveBayes 'лишние' вычисления и удалите код, что соответствует этим вычислениям. Под 'лишним' подразумеваются вещи, что не влияют на итоговое решение о принадлежности классу (значения вероятностей при этом могу стать некорректными, но в данном задании это допустимо).\n",
    "\n",
    "Напишите в клетке ниже код упрощенного 'классификатора Гаусса' и убедитесь, что его ответы (не значения вероятностей) совпадают с ответами классификатора из задания 1. Для сравнения ответов используйте функцию `assert_preds_correct`.\n",
    "\n",
    "Указание: работайте в предположении, что классы равновероятны.\n",
    "\n",
    "Подсказка: упростить необходимо метод `predict_single`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишите обновленный код модели здесь\n",
    "class NaiveGaussSimplified(NaiveGauss):\n",
    "\n",
    "    # Актуален\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        # Для просчёта безусловной вероятности используйте \n",
    "        # методы compute_prior и compute_likelihood.\n",
    "        return 1\n",
    "    \n",
    "    def predict_single(self, x, return_probs=False):\n",
    "        # Так как априорная вероятность P(x) не зависит от C для всех классов она одинаковая, а это значит, что не влияет на вероятность. \n",
    "        # https://en.wikipedia.org/wiki/Naive_Bayes_classifier  \n",
    "        probs = [self.compute_prior(c) * self.compute_likelihood(x, c) for c in range(self.n_classes)]\n",
    "        \n",
    "        return probs if return_probs else np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "my_ngs_clf = NaiveGaussSimplified(n_classes=3)\n",
    "my_ngs_clf.fit(x_train, y_train)\n",
    "ngs_Y = my_ngs_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "accuracy_score(ngs_Y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сравните вашу модель с моделью из задания 1\n",
    "accuracy_score(Y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объясните в комментариях к этой клетке суть проделанных изменений: почему удаленный код является лишним?\n",
    "\n",
    "# Так как априорная вероятность P(x) не зависит от C для всех классов она одинаковая, а это значит, что не влияет на вероятность.\n",
    "# https://en.wikipedia.org/wiki/Naive_Bayes_classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Наивный классификатор Байеса: мультиномиальное распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите недостающий код, создайте и обучите модель.\n",
    "\n",
    "Подсказка: в определении функции правдоподобия много факториалов. Для избежания численного переполнения посчитайте сначала логарифм функции правдоподобия (на бумаге), после примените экспоненту для получения значения вероятности.\n",
    "\n",
    "Пункты оценки:\n",
    "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
    "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True.\n",
    "\n",
    "Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "При желании данный класс можно переписать с нуля. Изменения должны сопровождаться комментариями.\n",
    "\"\"\"\n",
    "class NaiveMultinomial(NaiveBayes):\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        # Для просчёта безусловной вероятности используйте \n",
    "        # методы compute_prior и compute_likelihood.\n",
    "        # Напишите свой код здесь\n",
    "        return 1\n",
    "    \n",
    "    def compute_prior(self, c) -> float:\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "\n",
    "        return self.params['prior'][c]\n",
    "    \n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        log_factorial_N = gammaln(np.sum(x) + 1)\n",
    "        log_factorials_x = np.sum(gammaln(x + 1))\n",
    "        log_p = np.log(self.params['mean'][c])\n",
    "        \n",
    "        log_likelihood = log_factorial_N - log_factorials_x + np.sum(x * log_p)\n",
    "        return np.exp(log_likelihood)\n",
    "\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def _estimate_prior(self, y):\n",
    "        # Значения априорных вероятностей сохраните в `params` с ключом 'prior'\n",
    "        self.params['prior'] = np.array([np.mean(y == i) for i in range(self.n_classes)])\n",
    "\n",
    "    \n",
    "    def _estimate_params(self, x, y):\n",
    "        total_counts = np.array([x[y == c].sum(axis=0) + 1 for c in range(self.n_classes)])\n",
    "        class_sums = total_counts.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        self.params['mean'] = total_counts / class_sums\n",
    "\n",
    "    # def predict_single(self, x, return_probs=False) -> int:\n",
    "    #     probs = [self.compute_prior(c) * self.compute_likelihood(x, c) for c in range(self.n_classes)]\n",
    "        \n",
    "    #     return probs if return_probs else np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "nm_clf = NaiveMultinomial(n_classes=2)\n",
    "nm_clf.fit(x_train, y_train)\n",
    "nm_Y_preds = nm_clf.predict(x_test, return_probs=False)\n",
    "nm_Y_probs = nm_clf.predict(x_test, return_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (MultinomialNB)\n",
    "sklearn_ng_clf = MultinomialNB(alpha=1.0)\n",
    "sklearn_ng_clf.fit(x_train, y_train)\n",
    "sklearn_Y_preds = sklearn_ng_clf.predict(x_test)\n",
    "sklearn_Y_probs = sklearn_ng_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность написанной модели: 0.8173076923076923\n",
      "Точность библиотечной модели: 0.8173076923076923\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "print(f\"Точность написанной модели: {accuracy_score(nm_Y_preds, y_test)}\")\n",
    "print(f\"Точность библиотечной модели: {accuracy_score(sklearn_Y_preds, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совпадение предсказанных классов: True\n",
      "Совпадение предсказанных вероятностей: False\n"
     ]
    }
   ],
   "source": [
    "preds_correct = assert_preds_correct(nm_Y_preds, sklearn_Y_preds)\n",
    "prods_correct = assert_probs_correct(nm_Y_probs, sklearn_Y_probs)\n",
    "\n",
    "print(f\"Совпадение предсказанных классов: {preds_correct}\")\n",
    "print(f\"Совпадение предсказанных вероятностей: {prods_correct}\") \n",
    "# Различие вероятностей может быть в том, что в библиотечной моделе используется другая формула для мультиномиального классификатора"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
