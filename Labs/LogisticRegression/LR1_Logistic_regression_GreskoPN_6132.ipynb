{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        rng = np.random.default_rng(seed=0)\n",
    "        self.w = rng.normal(size=(dim, 1)) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        \n",
    "        x = x.dot(self.w) + self.b  # logits\n",
    "        p = sigmoid(x)  # probabilities\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        # y - np.array размернсоти [N]\n",
    "        #     Массив меток (правильных ответов).\n",
    "        assert len(x) == len(y), \\\n",
    "            \"Количество экземпляров в массиве X не равно количеству меток в массиве Y. \" + \\\n",
    "            f\"Полученные размеры: len(X) = {len(x)}, len(Y) = {len(y)}.\"\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        # Алгоритм градиентного спуска.\n",
    "        # Минимизируется бинарная кросс-энтропия.\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Применение логистической регрессии (несбалансированные данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Создание и обучение логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x196b13bfd00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте модель логистической регрессии и обучите её, используя метод fit.\n",
    "logisticRegression = LogisticRegression(x_train.shape[1])# создаем модель, передавая кол-во признаков у объекта\n",
    "logisticRegression.fit(x_train, y_train)# обучаем на тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045454545454545"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получите предсказания на тестовой выборке и оцените точность модели, \n",
    "# используя accuracy_score из пакета SciKit-Learn.\n",
    "Y = logisticRegression.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, Y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Анализ качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Допишите класс \"глупого классификатора\", что всегда предсказывает класс `0`. \n",
    "\n",
    "class DummyClassifier:\n",
    "    def __init__(self):\n",
    "        print('Hello, brother!')\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Должен возвращаться массив N предсказаний\n",
    "        return np.zeros((x.shape[0],))\n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, brother!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оцените точность \"глупого классификатора\", объясните результат.\n",
    "dummyClassifier = DummyClassifier()\n",
    "dummyClassifier.fit(x_train, y_train)\n",
    "Y_Dummy = dummyClassifier.predict(x_test)\n",
    "accuracy_Dummy = accuracy_score(y_test, Y_Dummy) \n",
    "accuracy_Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.0\n",
      "\n",
      "recall_score: 0.0\n",
      "\n",
      "precision_score: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Используйте дополнительные метрики (f1-score, recall, precision) из пакета sklearn для анализа \"глупого классификатора\".\n",
    "f1_score_Dummy = f1_score(y_test, Y_Dummy) \n",
    "recall_Dummy = recall_score(y_test, Y_Dummy) \n",
    "precision_score_Dummy = precision_score(y_test, Y_Dummy) \n",
    "print(f\"f1_score: {f1_score_Dummy}\\n\")\n",
    "print(f\"recall_score: {recall_Dummy}\\n\")\n",
    "print(f\"precision_score: {precision_score_Dummy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.4\n",
      "\n",
      "recall_score: 0.35\n",
      "\n",
      "precision_score: 0.4666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используя те же метрики, проанализируйте обученную вами модель логистической регрессии.\n",
    " \n",
    "print(f\"f1_score: {f1_score(y_test, Y)}\\n\")\n",
    "print(f\"recall_score: {recall_score(y_test, Y) }\\n\")\n",
    "print(f\"precision_score: {precision_score(y_test, Y)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объясните результат, описав его комментариями в этой клетке.\n",
    "\n",
    "# В наборе данных присутсвует дисбаланс классов, из-за которыго accuracy вернул не объективную оценку\n",
    "# Это показывает, что для получения более объективной оценки работы классификатора, необходимо использовать несколько метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Анализ набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of class 1: 20.0\n",
      "Count of class 2: 200.0 \n"
     ]
    }
   ],
   "source": [
    "# Посчитайте количество экземпляров данных для каждого класса.\n",
    "print(f\"Count of class 1: {sum(y_test)}\\nCount of class 2: {y_test.shape[0] - sum(y_test)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of class 1 resampled: 200.0\n",
      "Count of class 2 resampled: 200.0 \n"
     ]
    }
   ],
   "source": [
    "# Предложите способ улучшения качества модели. Подсказка: добавление дубликатов в данные.\n",
    "# Указание: не изменяйте тестовую выборку.\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "x_resampled, y_resampled = oversample.fit_resample(x_train, y_train)\n",
    "print(f\"Count of class 1 resampled: {sum(y_resampled)}\\nCount of class 2 resampled: {y_resampled.shape[0] - sum(y_resampled)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x196b13bd120>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием предложенных наработок.\n",
    "logisticRegressionForResampledData = LogisticRegression(x_resampled.shape[1])\n",
    "logisticRegressionForResampledData.fit(x_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.95\n",
      "\n",
      "f1_score: 0.7317073170731707\n",
      "\n",
      "recall_score: 0.75\n",
      "\n",
      "precision_score: 0.7142857142857143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "# Указание: постарайтесь сбалансировать данные таким образом, чтобы новая модель была ощутимо лучше старой.\n",
    "Y_resampled = logisticRegressionForResampledData.predict(x_test)\n",
    "\n",
    "print(f\"accuracy_score: {accuracy_score(y_test, Y_resampled)}\\n\")\n",
    "print(f\"f1_score: {f1_score(y_test, Y_resampled)}\\n\")\n",
    "print(f\"recall_score: {recall_score(y_test, Y_resampled)}\\n\")\n",
    "print(f\"precision_score: {precision_score(y_test, Y_resampled)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Применение логистической регрессии (нелинейные данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель но этом наборе данных.\n",
    "logisticRegression2 = LogisticRegression(x_train.shape[1])\n",
    "logisticRegression2.fit(x_train, y_train)\n",
    "Y2 = logisticRegression2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.57\n",
      "\n",
      "f1_score: 0.6194690265486725\n",
      "\n",
      "recall_score: 0.7777777777777778\n",
      "\n",
      "precision_score: 0.5147058823529411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проанализируйте качество модели.\n",
    "print(f\"accuracy_score: {accuracy_score(y_test, Y2)}\\n\")\n",
    "print(f\"f1_score: {f1_score(y_test, Y2)}\\n\")\n",
    "print(f\"recall_score: {recall_score(y_test, Y2)}\\n\")\n",
    "print(f\"precision_score: {precision_score(y_test, Y2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: попробуйте применить на исходных данных разные нелинейные функции (sin, tanh, ...).\n",
    "# Объедините трансформированные данные с исходными (важно: количество экземпляров в x_train не должно увеличиться).\n",
    "sign_x_train = x_train[:, 0].reshape(x_train.shape[0], 1)\n",
    "sign_y_train = np.cos(x_train[:, 1]).reshape(x_train.shape[0], 1)# применяю на втором признаке объектов из тренировочной выборки косинус\n",
    "\n",
    "sign_x_test = x_test[:, 0].reshape(x_test.shape[0], 1)\n",
    "sign_y_test = np.cos(x_test[:, 1]).reshape(x_test.shape[0], 1)# применяю на втором признаке объектов из тестовой выборки косинус\n",
    "\n",
    "x_train_transformed = np.hstack((sign_x_train, sign_y_train))\n",
    "x_test_transformed = np.hstack((sign_x_test, sign_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель с использованием наработок.\n",
    "sign_logisticRegression = LogisticRegression(x_train.shape[1])\n",
    "sign_logisticRegression.fit(x_train_transformed, y_train)\n",
    "sign_Y = sign_logisticRegression.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 1.0\n",
      "\n",
      "f1_score: 1.0\n",
      "\n",
      "recall_score: 1.0\n",
      "\n",
      "precision_score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "# Указание: постарайтесь добиться точности в 100%!\n",
    "print(f\"accuracy_score: {accuracy_score(y_test, sign_Y)}\\n\")\n",
    "print(f\"f1_score: {f1_score(y_test, sign_Y)}\\n\")\n",
    "print(f\"recall_score: {recall_score(y_test, sign_Y)}\\n\")\n",
    "print(f\"precision_score: {precision_score(y_test, sign_Y)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 'Упрощение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность: легко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Модифицируйте класс логистической регрессии так, чтобы в нём не использовалась сигмоида.\n",
    "То есть вывод о предсказанном классе должен делаться на основе значений \"до сигмоиды\".\n",
    "Вспомогательная ссылка: https://en.wikipedia.org/wiki/Logit\n",
    "\"\"\"\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b\n",
    "        return np.array(x > 0.0).astype('int32')# если x больше 0, то будет 1\n",
    "        \n",
    "    def fit(self, x, y, iters=100, lr=0.01):\n",
    "        y = y.reshape(-1, 1)\n",
    "        for _ in range(iters):\n",
    "            preds = self.predict(x)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перенесите обученные веса модели из пункта 1.3 в новую модель с модифицированным кодом\n",
    "ModifyLogisticRegression = LogisticRegression(x_resampled.shape[1])\n",
    "ModifyLogisticRegression.fit(x_resampled, y_resampled)\n",
    "Y_modify = ModifyLogisticRegression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of MODIFIED Logistic Regression:\n",
      "  accuracy_score: 0.9409090909090909\n",
      "  f1_score: 0.6976744186046512\n",
      "  recall_score: 0.75\n",
      "  precision_score: 0.6521739130434783\n",
      "\n",
      "Result of DEFAULT Logistic Regression:\n",
      "  accuracy_score: 0.95\n",
      "  f1_score: 0.7317073170731707\n",
      "  recall_score: 0.75\n",
      "  precision_score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Убедитесь, что предсказания модели с модифицированными кодом совпадают с предсказаниями\n",
    "# модели из пункта 1.3\n",
    "print(f\"Result of MODIFIED Logistic Regression:\")\n",
    "print(f\"  accuracy_score: {accuracy_score(y_test, Y_modify)}\")\n",
    "print(f\"  f1_score: {f1_score(y_test, Y_modify)}\")\n",
    "print(f\"  recall_score: {recall_score(y_test, Y_modify)}\")\n",
    "print(f\"  precision_score: {precision_score(y_test, Y_modify)}\")\n",
    "\n",
    "print(f\"\\nResult of DEFAULT Logistic Regression:\")\n",
    "print(f\"  accuracy_score: {accuracy_score(y_test, Y_resampled)}\")\n",
    "print(f\"  f1_score: {f1_score(y_test, Y_resampled)}\")\n",
    "print(f\"  recall_score: {recall_score(y_test, Y_resampled)}\")\n",
    "print(f\"  precision_score: {precision_score(y_test, Y_resampled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как видно из выбранных метрик, модифицированная модель предсказывает приблизительно с той же точностью, что и обычная**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 'Обобщение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите многоклассовый классификатор. Обучите его на наборе данных ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ансамбль логистических регрессий.</b> Сложность: супергерой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс, что инкапсулирует в себе `C` логистических регрессий, \n",
    "где `C` - количество классов. i-ая логистическая регрессия производит \n",
    "бинарную классификацию вида: все остальные классы и i-ый класс.\n",
    "\"\"\"\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        \"\"\"\n",
    "        n_classes: количество классов;\n",
    "        dim: количество признаков.\n",
    "        \"\"\"\n",
    "        self.n_classes = n_classes\n",
    "        self.dim = dim\n",
    "        # Для каждого класса создаем создаем свой экземпляр логистической регрессии \n",
    "        self.models = [LogisticRegression(dim) for _ in range(n_classes)]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "\n",
    "        # Получаем предсказания вероятностей для каждого класса\n",
    "        predictions = np.array([model.predict(x, probs=True).flatten() for i, model in enumerate(self.models)]).T\n",
    "        return np.argmax(predictions, axis=1)\n",
    "    \n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        for i in range(self.n_classes):\n",
    "            # Помечаем i-ый класс единицей остальные нулями \n",
    "            y_bin = (y == i).astype(int)\n",
    "            self.models[i].fit(x, y_bin, iters=iters, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор.\n",
    "n_classes = len(np.unique(y_train))\n",
    "multiclassLogisticRegression = MulticlassLogisticRegression(n_classes, np.shape(x_train)[1])\n",
    "multiclassLogisticRegression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of Multiple Logistic Regression:\n",
      "  accuracy_score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#  Оцените точность модели.\n",
    "Y_Multi = multiclassLogisticRegression.predict(x_test)\n",
    "\n",
    "print(f\"\\nResult of Multiple Logistic Regression:\")\n",
    "print(f\"  accuracy_score: {accuracy_score(y_test, Y_Multi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Softmax классификатор.</b> Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс классификатора, основанного на функции Softmax.\n",
    "Алгоритм работы данного классификатора:\n",
    "x - вектор (экземпляр данных) размерности dim.\n",
    "W - матрица весов размерности [dim, n_classes].\n",
    "\n",
    "Ответ классификатора формируется как:\n",
    "logits = x * W - матричное умножение\n",
    "p = softmax(logits)\n",
    "class_id = argmax(p)\n",
    "\n",
    "Для данного классификатора требуется модифицировать алгоритм обучения в методе fit.\n",
    "\n",
    "Вспомогательные ресурсы:\n",
    "https://en.wikipedia.org/wiki/Softmax_function\n",
    "https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n",
    "\"\"\"\n",
    "\n",
    "class SoftmaxClassificator:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели, посчитайте матрицу ошибок (выведите её с помощью matplotlib).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор на наборе данных из задания 1 (опционально). \n",
    "# Оцените точность модели, посчитайте матрицу ошибок (выведите её с помощью matplotlib).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
